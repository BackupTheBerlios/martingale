<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" href="SyntheticData/html-info.css" type="text/css">
</head>
<body>

<h1>TO DO</h1>

<h3>LiborMarketModel and drived classes:</h3>

the use of the cache XLvec is the only reason that the member function
XLvec(t,p) is not constant and that propagates through basically all the
Libor quantity member functions.
Reflect upon wether it's worth it or wether we should return from the stack.

<h3>INCLUDE ANALYIS</h3>

Get all definitions that need an include out of header files.
Use forward declarations instead of includes in header files.
Headers include much less and the forward declarations give us a much better 
picture of the dependencies.
<p>
Move all implementations out of headers. Then the declarations in the headers
will only use class and function names and these can be forward declared.
No forward declared functions can be called in a header and this includes the constructors
of forward declared classes in initialization lists!


<h3>7-13-03:</h3>

All files have been rewritten in this way and there is only one problem left before
linkage: No method Random::sTN()... Check if unwanted ifndef in source files.


<h3>7-17-03:</h3>


Include structure is still sloppy.
Why don't we have to qualify "cout" as "std::cout"??
Should we simply include &lt;string&gt; and &lt;iostream&gt;  in TypedefsMacros.h (and hence everywhere)?
Explore the difference between &lt;math.h&gt; and &lt;cmath&gt;.
<p>
LmmLattice2F,3F: implement a choice of wether we rescale the covariation matrix root to preserve
volatilities or not so we can test what works better.
<p>
Known problems:
<ul>
<li>std::ostream operator &lt;&lt; (std::ostream& os, const SomeType& x)
doesn't link but x->printSelf(os) works. Why is that?
</li>
<li>Examples::brownianMotionInBall(dim,T,dt,nPath) dies on array index out of bounds error.
</li>
</ul>


<h3>7-19-03:</h3>

<ul>
<li>Check if synthetic caplet prices are written correctly by the calibrator object.
   Why is calibration to caplet prices so atrocious?</li>

<li>Go after major memory leak detected by the old calibration routine.
   Check if matrix operations (especially pseudo square roots and log-Libor covariation
   matries deallocate everything properly.
</li>
<li>Implement  SlowLMMLattice, where the nodes do not cache the vector H, only the
   variables evolved in the lattice from which this vector can be computed.
   This uses much less memory at the expense of computational effort.
   We can have millions of nodes.</li>
   
<li>Implementation of Bermudan style options in lattice both Libor and otherwise. </li>

<li>Redesign the matrix classes using traits as template parameters to shrink the code size.
     Use allocaters for upper triangular, lower triangular, symmetric etc matrices.
     Find out about iterator design (otherwise methods rowBegin(i), rowEnd(i)).
     Since we don't have matrix expressions to deal with "#define MATRIX-MAX-DIM"
     limit all matrices to this size and create a static workspace of that size. Then write to that 
     workspace in matrix products (saves memory allocation).</li>
</ul>





</body>
</html>

